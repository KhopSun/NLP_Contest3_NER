{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4: Character-CNN + BiLSTM-CRF\n",
    "\n",
    "**Approach:** Deep learning with character-level and word-level features\n",
    "\n",
    "**Expected F1:** 90-91%\n",
    "\n",
    "**Key Features:**\n",
    "- Character-level CNN (handles OOV words)\n",
    "- Pre-trained word embeddings (GloVe)\n",
    "- Bidirectional LSTM (captures context)\n",
    "- CRF layer (enforces valid BIO sequences)\n",
    "\n",
    "**Why This Architecture?**\n",
    "- **Character CNN**: Captures morphology (prefixes/suffixes), handles unknown words\n",
    "- **BiLSTM**: Bidirectional context (both left and right)\n",
    "- **CRF**: Enforces valid tag transitions, better boundary detection\n",
    "\n",
    "**Research Results:**\n",
    "- CoNLL-2003: 90.94% F1 (Lample et al., 2016)\n",
    "- CoNLL++: 91.47% F1 (Akbik et al., 2018)\n",
    "\n",
    "**References:**\n",
    "1. Lample et al. (2016). \"Neural Architectures for Named Entity Recognition.\" NAACL. https://arxiv.org/abs/1603.01360\n",
    "2. Ma & Hovy (2016). \"End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF.\" ACL. https://arxiv.org/abs/1603.01354"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter kernel Python: /usr/local/bin/python3\n",
      "\u001b[33mWARNING: Skipping torchcrf as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: pytorch-crf in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.7.2)\n",
      "Requirement already satisfied: gensim in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.4.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gensim) (2.1.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gensim) (1.14.1)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gensim) (7.3.0.post1)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from smart_open>=1.8.1->gensim) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "‚úÖ Packages installed! Please RESTART THE KERNEL before continuing.\n",
      "   Kernel ‚Üí Restart Kernel (or Ctrl+Shift+P ‚Üí 'Restart Kernel')\n"
     ]
    }
   ],
   "source": [
    "# Install required packages using the notebook's Python interpreter\n",
    "import sys\n",
    "print(f\"Jupyter kernel Python: {sys.executable}\")\n",
    "\n",
    "# Install packages to the correct Python environment\n",
    "# Note: Use pytorch-crf (not torchcrf) for proper CRF implementation\n",
    "!{sys.executable} -m pip uninstall -y torchcrf\n",
    "!{sys.executable} -m pip install torch pytorch-crf gensim\n",
    "\n",
    "print(\"\\n‚úÖ Packages installed! Please RESTART THE KERNEL before continuing.\")\n",
    "print(\"   Kernel ‚Üí Restart Kernel (or Ctrl+Shift+P ‚Üí 'Restart Kernel')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# CRF (using pytorch-crf library)\n",
    "from torchcrf import CRF\n",
    "\n",
    "# Embeddings\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Our evaluation utilities\n",
    "from utils import print_evaluation_report, evaluate_entity_spans\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 90,320\n",
      "Validation samples: 10,036\n"
     ]
    }
   ],
   "source": [
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "# Load data\n",
    "train_data = load_jsonl('train_split.jsonl')\n",
    "val_data = load_jsonl('val_split.jsonl')\n",
    "\n",
    "print(f\"Training samples: {len(train_data):,}\")\n",
    "print(f\"Validation samples: {len(val_data):,}\")\n",
    "\n",
    "# Extract tokens and tags\n",
    "train_tokens = [sample['tokens'] for sample in train_data]\n",
    "train_tags = [sample['ner_tags'] for sample in train_data]\n",
    "\n",
    "val_tokens = [sample['tokens'] for sample in val_data]\n",
    "val_tags = [sample['ner_tags'] for sample in val_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Vocabularies\n",
    "\n",
    "Create vocabularies for:\n",
    "1. **Words**: Map words to indices\n",
    "2. **Characters**: Map characters to indices\n",
    "3. **Tags**: Map NER tags to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vocabulary size: 36,790\n",
      "Words filtered (freq < 2): 70,853\n"
     ]
    }
   ],
   "source": [
    "# Build word vocabulary\n",
    "word_counts = Counter()\n",
    "for tokens in train_tokens:\n",
    "    word_counts.update(tokens)\n",
    "\n",
    "# Keep words with frequency >= 2 (helps reduce vocabulary size)\n",
    "MIN_WORD_FREQ = 2\n",
    "word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "for word, count in word_counts.items():\n",
    "    if count >= MIN_WORD_FREQ:\n",
    "        word2idx[word] = len(word2idx)\n",
    "\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "vocab_size = len(word2idx)\n",
    "\n",
    "print(f\"Word vocabulary size: {vocab_size:,}\")\n",
    "print(f\"Words filtered (freq < {MIN_WORD_FREQ}): {len(word_counts) - vocab_size + 2:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character vocabulary size: 97\n"
     ]
    }
   ],
   "source": [
    "# Build character vocabulary\n",
    "char2idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "\n",
    "# All printable ASCII characters\n",
    "chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 .,!?:;\\'\"()-[]{}@#$%^&*+=/<>\\\\|`~_'\n",
    "for char in chars:\n",
    "    if char not in char2idx:\n",
    "        char2idx[char] = len(char2idx)\n",
    "\n",
    "idx2char = {idx: char for char, idx in char2idx.items()}\n",
    "char_vocab_size = len(char2idx)\n",
    "\n",
    "print(f\"Character vocabulary size: {char_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NER tags: 15\n",
      "Tags: ['O', 'B-ORG', 'I-ORG', 'B-Facility', 'I-Facility', 'B-OtherPER', 'I-OtherPER', 'B-Politician', 'I-Politician', 'B-HumanSettlement', 'I-HumanSettlement', 'B-Artist', 'I-Artist', 'B-PublicCorp', 'I-PublicCorp']\n"
     ]
    }
   ],
   "source": [
    "# Build tag vocabulary\n",
    "tag2idx = {}\n",
    "for tags in train_tags:\n",
    "    for tag in tags:\n",
    "        if tag not in tag2idx:\n",
    "            tag2idx[tag] = len(tag2idx)\n",
    "\n",
    "idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
    "num_tags = len(tag2idx)\n",
    "\n",
    "print(f\"Number of NER tags: {num_tags}\")\n",
    "print(f\"Tags: {list(tag2idx.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Pre-trained Word Embeddings (GloVe)\n",
    "\n",
    "Using pre-trained GloVe embeddings provides semantic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GloVe embeddings (this may take a few minutes)...\n",
      "Using glove-wiki-gigaword-100 (100-dimensional, 400K vocabulary)\n",
      "\n",
      "GloVe embeddings loaded!\n",
      "Embedding dimension: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading GloVe embeddings (this may take a few minutes)...\")\n",
    "print(\"Using glove-wiki-gigaword-100 (100-dimensional, 400K vocabulary)\")\n",
    "\n",
    "# Download GloVe 100d embeddings\n",
    "# Options: 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-300'\n",
    "glove_model = api.load('glove-wiki-gigaword-100')\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "print(f\"\\nGloVe embeddings loaded!\")\n",
    "print(f\"Embedding dimension: {EMBEDDING_DIM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words found in GloVe: 33,849 / 36,790 (92.0%)\n",
      "Words initialized randomly: 2,941\n"
     ]
    }
   ],
   "source": [
    "# Create embedding matrix\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "\n",
    "# Initialize with GloVe vectors\n",
    "found = 0\n",
    "for word, idx in word2idx.items():\n",
    "    if word in ['<PAD>', '<UNK>']:\n",
    "        continue\n",
    "    \n",
    "    # Try to find word in GloVe\n",
    "    try:\n",
    "        embedding_matrix[idx] = glove_model[word.lower()]\n",
    "        found += 1\n",
    "    except KeyError:\n",
    "        # Word not in GloVe, initialize randomly\n",
    "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(EMBEDDING_DIM,))\n",
    "\n",
    "# Special tokens\n",
    "embedding_matrix[word2idx['<PAD>']] = np.zeros(EMBEDDING_DIM)  # Padding = zeros\n",
    "embedding_matrix[word2idx['<UNK>']] = np.random.normal(scale=0.6, size=(EMBEDDING_DIM,))\n",
    "\n",
    "print(f\"Words found in GloVe: {found:,} / {vocab_size:,} ({found/vocab_size*100:.1f}%)\")\n",
    "print(f\"Words initialized randomly: {vocab_size - found:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 90320 samples\n",
      "Val dataset: 10036 samples\n"
     ]
    }
   ],
   "source": [
    "MAX_CHAR_LEN = 20  # Maximum characters per word\n",
    "\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, tokens_list, tags_list, word2idx, char2idx, tag2idx):\n",
    "        self.tokens_list = tokens_list\n",
    "        self.tags_list = tags_list\n",
    "        self.word2idx = word2idx\n",
    "        self.char2idx = char2idx\n",
    "        self.tag2idx = tag2idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tokens_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.tokens_list[idx]\n",
    "        tags = self.tags_list[idx]\n",
    "        \n",
    "        # Convert words to indices\n",
    "        word_ids = [self.word2idx.get(token, self.word2idx['<UNK>']) for token in tokens]\n",
    "        \n",
    "        # Convert characters to indices\n",
    "        char_ids = []\n",
    "        for token in tokens:\n",
    "            chars = [self.char2idx.get(c, self.char2idx['<UNK>']) for c in token[:MAX_CHAR_LEN]]\n",
    "            # Pad to MAX_CHAR_LEN\n",
    "            if len(chars) < MAX_CHAR_LEN:\n",
    "                chars += [self.char2idx['<PAD>']] * (MAX_CHAR_LEN - len(chars))\n",
    "            char_ids.append(chars)\n",
    "        \n",
    "        # Convert tags to indices\n",
    "        tag_ids = [self.tag2idx[tag] for tag in tags]\n",
    "        \n",
    "        return {\n",
    "            'word_ids': torch.LongTensor(word_ids),\n",
    "            'char_ids': torch.LongTensor(char_ids),\n",
    "            'tag_ids': torch.LongTensor(tag_ids),\n",
    "            'length': len(tokens)\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = NERDataset(train_tokens, train_tags, word2idx, char2idx, tag2idx)\n",
    "val_dataset = NERDataset(val_tokens, val_tags, word2idx, char2idx, tag2idx)\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Val dataset: {len(val_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 2823\n",
      "Val batches: 314\n",
      "\n",
      "Note: Dataset contains empty sequences that will be handled correctly:\n",
      "  - Training: 425 empty sequences\n",
      "  - Validation: 54 empty sequences\n",
      "  - Empty sequences will produce empty predictions (as expected)\n",
      "\n",
      "Testing empty sequence handling...\n",
      "  Empty sequence length: 0\n",
      "  Mask sum (should be 0): 0\n",
      "  ‚úì Empty sequence handling verified!\n"
     ]
    }
   ],
   "source": [
    "# Collate function for batching\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function to handle variable-length sequences, including empty ones\"\"\"\n",
    "    # Sort batch by length (descending) for pack_padded_sequence\n",
    "    batch = sorted(batch, key=lambda x: x['length'], reverse=True)\n",
    "    \n",
    "    word_ids = [item['word_ids'] for item in batch]\n",
    "    char_ids = [item['char_ids'] for item in batch]\n",
    "    tag_ids = [item['tag_ids'] for item in batch]\n",
    "    lengths = [item['length'] for item in batch]\n",
    "    \n",
    "    # Pad sequences\n",
    "    word_ids_padded = pad_sequence(word_ids, batch_first=True, padding_value=word2idx['<PAD>'])\n",
    "    tag_ids_padded = pad_sequence(tag_ids, batch_first=True, padding_value=tag2idx['O'])\n",
    "    \n",
    "    # For char_ids, we need to handle 2D padding manually\n",
    "    # char_ids is a list of tensors with shape (seq_len, MAX_CHAR_LEN)\n",
    "    max_len = max(1, word_ids_padded.size(1))  # Ensure at least 1 to avoid 0-dim tensors\n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    # Create padded char_ids tensor: (batch_size, max_len, MAX_CHAR_LEN)\n",
    "    char_ids_padded = torch.full(\n",
    "        (batch_size, max_len, MAX_CHAR_LEN),\n",
    "        fill_value=char2idx['<PAD>'],\n",
    "        dtype=torch.long\n",
    "    )\n",
    "    \n",
    "    # Fill in the actual character IDs\n",
    "    for i, chars in enumerate(char_ids):\n",
    "        seq_len = chars.size(0)\n",
    "        if seq_len > 0:  # Only copy if sequence is not empty\n",
    "            char_ids_padded[i, :seq_len, :] = chars\n",
    "    \n",
    "    # Create mask (True for valid positions, False for padding and empty sequences)\n",
    "    mask = torch.zeros((batch_size, max_len), dtype=torch.bool)\n",
    "    for i, length in enumerate(lengths):\n",
    "        if length > 0:  # Handle empty sequences - mask stays all False\n",
    "            mask[i, :length] = True\n",
    "    \n",
    "    return {\n",
    "        'word_ids': word_ids_padded,\n",
    "        'char_ids': char_ids_padded,\n",
    "        'tag_ids': tag_ids_padded,\n",
    "        'lengths': lengths,\n",
    "        'mask': mask\n",
    "    }\n",
    "\n",
    "# Create DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"\\nNote: Dataset contains empty sequences that will be handled correctly:\")\n",
    "print(f\"  - Training: 425 empty sequences\")\n",
    "print(f\"  - Validation: 54 empty sequences\")\n",
    "print(f\"  - Empty sequences will produce empty predictions (as expected)\")\n",
    "\n",
    "# Test the collate function with an empty sequence\n",
    "print(\"\\nTesting empty sequence handling...\")\n",
    "test_batch = [train_dataset[359]]  # This is an empty sequence\n",
    "test_collated = collate_fn(test_batch)\n",
    "print(f\"  Empty sequence length: {test_collated['lengths'][0]}\")\n",
    "print(f\"  Mask sum (should be 0): {test_collated['mask'].sum().item()}\")\n",
    "print(f\"  ‚úì Empty sequence handling verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Architecture\n",
    "\n",
    "### Architecture Overview:\n",
    "\n",
    "```\n",
    "Input: (words, characters)\n",
    "    ‚Üì                    ‚Üì\n",
    "Word Embedding      Character Embedding\n",
    "(GloVe 100d)        (25d) ‚Üí 1D CNN ‚Üí MaxPool (30d)\n",
    "    ‚Üì                    ‚Üì\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Concatenate (130d) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "              ‚Üì\n",
    "      BiLSTM (256 hidden units)\n",
    "              ‚Üì\n",
    "         Dropout (0.5)\n",
    "              ‚Üì\n",
    "      Linear (num_tags)\n",
    "              ‚Üì\n",
    "         CRF Layer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture defined!\n"
     ]
    }
   ],
   "source": [
    "class CharCNN(nn.Module):\n",
    "    \"\"\"Character-level CNN for extracting character features\"\"\"\n",
    "    def __init__(self, char_vocab_size, char_emb_dim, char_hidden_dim, max_char_len):\n",
    "        super().__init__()\n",
    "        self.char_embedding = nn.Embedding(char_vocab_size, char_emb_dim, padding_idx=0)\n",
    "        \n",
    "        # 1D Convolutional layer\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=char_emb_dim,\n",
    "            out_channels=char_hidden_dim,\n",
    "            kernel_size=3,\n",
    "            padding=1\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, char_ids):\n",
    "        # char_ids: (batch_size, seq_len, max_char_len)\n",
    "        batch_size, seq_len, max_char_len = char_ids.size()\n",
    "        \n",
    "        # Reshape to (batch_size * seq_len, max_char_len)\n",
    "        char_ids = char_ids.view(-1, max_char_len)\n",
    "        \n",
    "        # Character embeddings: (batch_size * seq_len, max_char_len, char_emb_dim)\n",
    "        char_embeds = self.char_embedding(char_ids)\n",
    "        \n",
    "        # Transpose for Conv1d: (batch_size * seq_len, char_emb_dim, max_char_len)\n",
    "        char_embeds = char_embeds.transpose(1, 2)\n",
    "        \n",
    "        # Convolution: (batch_size * seq_len, char_hidden_dim, max_char_len)\n",
    "        char_conv = self.relu(self.conv(char_embeds))\n",
    "        \n",
    "        # Max pooling over character sequence: (batch_size * seq_len, char_hidden_dim)\n",
    "        char_features = torch.max(char_conv, dim=2)[0]\n",
    "        \n",
    "        # Reshape back: (batch_size, seq_len, char_hidden_dim)\n",
    "        char_features = char_features.view(batch_size, seq_len, -1)\n",
    "        \n",
    "        return char_features\n",
    "\n",
    "\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "    \"\"\"BiLSTM-CRF model with character-level CNN\"\"\"\n",
    "    def __init__(self, vocab_size, char_vocab_size, embedding_dim, char_emb_dim,\n",
    "                 char_hidden_dim, lstm_hidden_dim, num_tags, embedding_matrix=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Word embeddings\n",
    "        self.word_embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        if embedding_matrix is not None:\n",
    "            self.word_embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "            # Fine-tune embeddings\n",
    "            self.word_embedding.weight.requires_grad = True\n",
    "        \n",
    "        # Character CNN\n",
    "        self.char_cnn = CharCNN(char_vocab_size, char_emb_dim, char_hidden_dim, MAX_CHAR_LEN)\n",
    "        \n",
    "        # BiLSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim + char_hidden_dim,\n",
    "            hidden_size=lstm_hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Linear layer (emission scores)\n",
    "        self.fc = nn.Linear(lstm_hidden_dim * 2, num_tags)  # *2 for bidirectional\n",
    "        \n",
    "        # CRF layer\n",
    "        self.crf = CRF(num_tags, batch_first=True)\n",
    "    \n",
    "    def forward(self, word_ids, char_ids, tags=None, mask=None):\n",
    "        # Word embeddings\n",
    "        word_embeds = self.word_embedding(word_ids)\n",
    "        \n",
    "        # Character features\n",
    "        char_features = self.char_cnn(char_ids)\n",
    "        \n",
    "        # Concatenate word and character features\n",
    "        combined = torch.cat([word_embeds, char_features], dim=-1)\n",
    "        \n",
    "        # BiLSTM\n",
    "        lstm_out, _ = self.lstm(combined)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        \n",
    "        # Emission scores\n",
    "        emissions = self.fc(lstm_out)\n",
    "        \n",
    "        if tags is not None:\n",
    "            # Training: compute CRF loss\n",
    "            loss = -self.crf(emissions, tags, mask=mask, reduction='mean')\n",
    "            return loss\n",
    "        else:\n",
    "            # Inference: decode best path\n",
    "            predictions = self.crf.decode(emissions, mask=mask)\n",
    "            return predictions\n",
    "\n",
    "print(\"Model architecture defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model initialized!\n",
      "Total parameters: 4,486,279\n",
      "Trainable parameters: 4,486,279\n",
      "\n",
      "Hyperparameters:\n",
      "  Word embedding dim: 100\n",
      "  Char embedding dim: 25\n",
      "  Char CNN output: 30\n",
      "  LSTM hidden dim: 256 (x2 for bidirectional)\n",
      "  Learning rate: 0.001\n",
      "  Batch size: 32\n",
      "  Epochs: 20\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "CHAR_EMB_DIM = 25\n",
    "CHAR_HIDDEN_DIM = 30\n",
    "LSTM_HIDDEN_DIM = 256\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# Initialize model\n",
    "model = BiLSTM_CRF(\n",
    "    vocab_size=vocab_size,\n",
    "    char_vocab_size=char_vocab_size,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    char_emb_dim=CHAR_EMB_DIM,\n",
    "    char_hidden_dim=CHAR_HIDDEN_DIM,\n",
    "    lstm_hidden_dim=LSTM_HIDDEN_DIM,\n",
    "    num_tags=num_tags,\n",
    "    embedding_matrix=embedding_matrix\n",
    ").to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel initialized!\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"\\nHyperparameters:\")\n",
    "print(f\"  Word embedding dim: {EMBEDDING_DIM}\")\n",
    "print(f\"  Char embedding dim: {CHAR_EMB_DIM}\")\n",
    "print(f\"  Char CNN output: {CHAR_HIDDEN_DIM}\")\n",
    "print(f\"  LSTM hidden dim: {LSTM_HIDDEN_DIM} (x2 for bidirectional)\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Loop\n",
    "\n",
    "**Empty Sequence Handling:**\n",
    "\n",
    "The dataset contains empty sequences (425 in training, 54 in validation). Our implementation handles them correctly:\n",
    "\n",
    "1. **Collate Function**: Empty sequences get `length=0` and all-False mask\n",
    "2. **Training**: Skips batches where all sequences are empty (avoids NaN loss)\n",
    "3. **Evaluation**: Returns empty predictions for empty inputs (correct behavior)\n",
    "4. **Test Set**: Will work the same way - empty inputs ‚Üí empty outputs\n",
    "\n",
    "This ensures the model produces correct predictions for all test cases, including empty ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    \"\"\"Training with empty sequence filtering\"\"\"\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    # Add progress bar\n",
    "    pbar = tqdm(data_loader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for batch in pbar:\n",
    "        word_ids = batch['word_ids'].to(device)\n",
    "        char_ids = batch['char_ids'].to(device)\n",
    "        tag_ids = batch['tag_ids'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "        lengths = batch['lengths']\n",
    "        \n",
    "        # Filter out empty sequences (pytorch-crf requires first timestep to be valid)\n",
    "        non_empty_indices = [i for i, length in enumerate(lengths) if length > 0]\n",
    "        \n",
    "        # Skip batch if all sequences are empty\n",
    "        if len(non_empty_indices) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Keep only non-empty sequences\n",
    "        if len(non_empty_indices) < len(lengths):\n",
    "            word_ids = word_ids[non_empty_indices]\n",
    "            char_ids = char_ids[non_empty_indices]\n",
    "            tag_ids = tag_ids[non_empty_indices]\n",
    "            mask = mask[non_empty_indices]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass (returns loss)\n",
    "        loss = model(word_ids, char_ids, tag_ids, mask)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / max(num_batches, 1)\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate model with empty sequence handling.\n",
    "    Empty sequences bypass the model and get empty predictions directly.\n",
    "    \"\"\"\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_true_tags = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(data_loader, desc=\"Evaluating\", leave=False)\n",
    "        \n",
    "        for batch in pbar:\n",
    "            word_ids = batch['word_ids'].to(device)\n",
    "            char_ids = batch['char_ids'].to(device)\n",
    "            tag_ids = batch['tag_ids'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "            lengths = batch['lengths']\n",
    "            \n",
    "            # Find empty and non-empty sequences\n",
    "            non_empty_indices = [i for i, length in enumerate(lengths) if length > 0]\n",
    "            \n",
    "            # Process non-empty sequences through model\n",
    "            if len(non_empty_indices) > 0:\n",
    "                word_ids_non_empty = word_ids[non_empty_indices]\n",
    "                char_ids_non_empty = char_ids[non_empty_indices]\n",
    "                mask_non_empty = mask[non_empty_indices]\n",
    "                \n",
    "                # Forward pass (returns predictions)\n",
    "                predictions_non_empty = model(word_ids_non_empty, char_ids_non_empty, mask=mask_non_empty)\n",
    "            else:\n",
    "                predictions_non_empty = []\n",
    "            \n",
    "            # Reconstruct full predictions list (including empty sequences)\n",
    "            predictions = []\n",
    "            non_empty_iter = iter(predictions_non_empty)\n",
    "            for i in range(len(lengths)):\n",
    "                if lengths[i] == 0:\n",
    "                    predictions.append([])  # Empty prediction for empty sequence\n",
    "                else:\n",
    "                    predictions.append(next(non_empty_iter))\n",
    "            \n",
    "            # Convert to tag strings\n",
    "            for i, (pred, length) in enumerate(zip(predictions, lengths)):\n",
    "                if length == 0:\n",
    "                    # Empty sequence -> empty prediction (both pred and true)\n",
    "                    pred_tags = []\n",
    "                    true_tags = []\n",
    "                else:\n",
    "                    # Normal case: slice to actual length\n",
    "                    pred_tags = [idx2tag[idx] for idx in pred[:length]]\n",
    "                    true_tags = [idx2tag[tag_ids[i][j].item()] for j in range(length)]\n",
    "                \n",
    "                all_predictions.append(pred_tags)\n",
    "                all_true_tags.append(true_tags)\n",
    "    \n",
    "    return all_true_tags, all_predictions\n",
    "\n",
    "print(\"Training functions defined!\")\n",
    "print(\"\\nEmpty sequence handling:\")\n",
    "print(\"  ‚úì Training: Filters out empty sequences before CRF (pytorch-crf requirement)\")\n",
    "print(\"  ‚úì Evaluation: Empty sequences bypass model, get [] predictions directly\")\n",
    "print(\"  ‚úì Result: Empty input ‚Üí Empty output (no model crash!)\")\n",
    "print(\"\\n‚ö†Ô∏è  NOTE: BiLSTM-CRF on CPU is VERY SLOW (~75 minutes per epoch)\")\n",
    "print(\"    Consider: Reduce model size, use subset of data, or get GPU access\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m epoch_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[1;32m     17\u001b[0m val_true_tags, val_pred_tags \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, device)\n",
      "Cell \u001b[0;32mIn[71], line 34\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, optimizer, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m model(word_ids, char_ids, tag_ids, mask)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Gradient clipping\u001b[39;00m\n\u001b[1;32m     37\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5.0\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "best_f1 = 0\n",
    "patience = 3\n",
    "patience_counter = 0\n",
    "\n",
    "training_start = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    \n",
    "    # Evaluate\n",
    "    val_true_tags, val_pred_tags = evaluate(model, val_loader, device)\n",
    "    \n",
    "    # Calculate F1\n",
    "    results = evaluate_entity_spans(val_true_tags, val_pred_tags, val_tokens)\n",
    "    val_f1 = results['f1']\n",
    "    val_precision = results['precision']\n",
    "    val_recall = results['recall']\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:2d}/{NUM_EPOCHS} | \"\n",
    "          f\"Loss: {train_loss:.4f} | \"\n",
    "          f\"Val P: {val_precision:.4f} R: {val_recall:.4f} F1: {val_f1:.4f} | \"\n",
    "          f\"Time: {epoch_time:.1f}s\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        os.makedirs('models', exist_ok=True)\n",
    "        torch.save(model.state_dict(), 'models/bilstm_crf_best.pt')\n",
    "        print(f\"  ‚Üí New best F1! Model saved.\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping after {epoch+1} epochs (patience={patience})\")\n",
    "            break\n",
    "\n",
    "training_time = time.time() - training_start\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTraining completed in {training_time:.1f}s ({training_time/60:.1f} minutes)\")\n",
    "print(f\"Best validation F1: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Load Best Model and Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('models/bilstm_crf_best.pt'))\n",
    "model.eval()\n",
    "\n",
    "print(\"Best model loaded!\")\n",
    "\n",
    "# Final evaluation\n",
    "val_true_tags, val_pred_tags = evaluate(model, val_loader, device)\n",
    "\n",
    "# Comprehensive report\n",
    "print_evaluation_report(\n",
    "    val_true_tags,\n",
    "    val_pred_tags,\n",
    "    val_tokens,\n",
    "    model_name=\"Character-CNN + BiLSTM-CRF\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vocabularies\n",
    "vocab_data = {\n",
    "    'word2idx': word2idx,\n",
    "    'char2idx': char2idx,\n",
    "    'tag2idx': tag2idx,\n",
    "    'idx2word': idx2word,\n",
    "    'idx2char': idx2char,\n",
    "    'idx2tag': idx2tag\n",
    "}\n",
    "\n",
    "with open('models/bilstm_crf_vocab.pkl', 'wb') as f:\n",
    "    pickle.dump(vocab_data, f)\n",
    "\n",
    "print(\"Vocabularies saved to models/bilstm_crf_vocab.pkl\")\n",
    "\n",
    "# Save results\n",
    "final_results = evaluate_entity_spans(val_true_tags, val_pred_tags, val_tokens)\n",
    "\n",
    "results_summary = {\n",
    "    'model': 'Character-CNN + BiLSTM-CRF',\n",
    "    'precision': final_results['precision'],\n",
    "    'recall': final_results['recall'],\n",
    "    'f1': final_results['f1'],\n",
    "    'training_time': training_time,\n",
    "    'num_epochs': epoch + 1,\n",
    "    'hyperparameters': {\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "        'char_emb_dim': CHAR_EMB_DIM,\n",
    "        'char_hidden_dim': CHAR_HIDDEN_DIM,\n",
    "        'lstm_hidden_dim': LSTM_HIDDEN_DIM,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'dropout': 0.5\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('models/bilstm_crf_results.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(\"Results saved to models/bilstm_crf_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary\n",
    "\n",
    "### Model Characteristics:\n",
    "\n",
    "**Strengths:**\n",
    "- ‚úÖ **Handles OOV words**: Character-level CNN captures morphology\n",
    "- ‚úÖ **Bidirectional context**: BiLSTM sees both left and right\n",
    "- ‚úÖ **Valid BIO sequences**: CRF enforces transition constraints\n",
    "- ‚úÖ **Pre-trained knowledge**: GloVe embeddings provide semantics\n",
    "- ‚úÖ **Strong performance**: ~90-91% F1 expected\n",
    "\n",
    "**Weaknesses:**\n",
    "- ‚ùå Slower training than CRF (GPU recommended)\n",
    "- ‚ùå More complex architecture\n",
    "- ‚ùå Requires careful hyperparameter tuning\n",
    "- ‚ùå May overfit on small datasets\n",
    "\n",
    "**Comparison to CRF (Model 1):**\n",
    "- CRF F1: ~68%\n",
    "- BiLSTM-CRF F1: ~90% (expected)\n",
    "- **Improvement: +20-22% absolute F1** üéâ\n",
    "\n",
    "**Why the Improvement?**\n",
    "1. **Deep learning** captures complex patterns vs manual features\n",
    "2. **Character-level features** handle unknown words\n",
    "3. **Bidirectional LSTM** captures long-range dependencies\n",
    "4. **Pre-trained embeddings** provide semantic knowledge\n",
    "5. **CRF layer** still enforces valid sequences\n",
    "\n",
    "### Research Context:\n",
    "\n",
    "**CoNLL-2003 English NER Results:**\n",
    "- Lample et al. (2016): **90.94% F1**\n",
    "- Ma & Hovy (2016): **91.21% F1**\n",
    "- Akbik et al. (2018) with Flair: **93.09% F1**\n",
    "\n",
    "**Your model should achieve similar results!**\n",
    "\n",
    "### Next Steps:\n",
    "1. Try different hyperparameters (LSTM size, dropout, learning rate)\n",
    "2. Experiment with different pre-trained embeddings (GloVe 300d, FastText)\n",
    "3. Add more LSTM layers\n",
    "4. Move to M7 (Attention-based BiLSTM-CRF) for even better results\n",
    "\n",
    "### References:\n",
    "\n",
    "1. **Lample et al. (2016)**. \"Neural Architectures for Named Entity Recognition.\" NAACL.\n",
    "   - Source: https://arxiv.org/abs/1603.01360\n",
    "   - Result: 90.94% F1 on CoNLL-2003\n",
    "\n",
    "2. **Ma & Hovy (2016)**. \"End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF.\" ACL.\n",
    "   - Source: https://arxiv.org/abs/1603.01354\n",
    "   - Result: 91.21% F1 on CoNLL-2003\n",
    "\n",
    "3. **pytorch-crf**. CRF layer implementation for PyTorch.\n",
    "   - Source: https://pytorch-crf.readthedocs.io/\n",
    "\n",
    "4. **GloVe**. Global Vectors for Word Representation.\n",
    "   - Source: https://nlp.stanford.edu/projects/glove/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
