{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 (Lample 2016): BiLSTM-CRF with Char-BiLSTM\n",
    "\n",
    "**This notebook EXACTLY replicates Lample et al. (2016) hyperparameters**\n",
    "\n",
    "**Paper**: \"Neural Architectures for Named Entity Recognition\" (NAACL 2016)\n",
    "\n",
    "**Original Results on CoNLL-2003**: 90.94% F1\n",
    "\n",
    "## Key Difference from Ma & Hovy (2016):\n",
    "\n",
    "**Character Encoding:**\n",
    "- **Lample (2016)**: Character-level **BiLSTM** (forward + backward LSTM over characters)\n",
    "- **Ma & Hovy (2016)**: Character-level **CNN** (convolution + max pooling)\n",
    "\n",
    "Both papers use BiLSTM + CRF at the word level, but differ in how they encode characters.\n",
    "\n",
    "## Hyperparameters from Paper:\n",
    "\n",
    "| Component | Lample et al. (2016) |\n",
    "|-----------|---------------------|\n",
    "| Char encoding | **BiLSTM** (25d hidden per direction) |\n",
    "| Word LSTM hidden | **100** per direction |\n",
    "| Optimizer | **SGD + momentum** |\n",
    "| Learning rate | **0.01** |\n",
    "| Dropout | **0.5** |\n",
    "| Gradient clipping | **5.0** |\n",
    "\n",
    "**Reference**: Lample, G., Ballesteros, M., Subramanian, S., Kawakami, K., & Dyer, C. (2016). Neural architectures for named entity recognition. arXiv preprint arXiv:1603.01360."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: /usr/local/bin/python3\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: pytorch-crf in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.7.2)\n",
      "Requirement already satisfied: gensim in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.4.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gensim) (2.1.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gensim) (1.14.1)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gensim) (7.3.0.post1)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from smart_open>=1.8.1->gensim) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "âœ… Packages installed!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "import sys\n",
    "print(f\"Python: {sys.executable}\")\n",
    "\n",
    "!{sys.executable} -m pip install torch pytorch-crf gensim tqdm\n",
    "\n",
    "print(\"\\nâœ… Packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# CRF\n",
    "from torchcrf import CRF\n",
    "\n",
    "# Embeddings\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Our evaluation utilities\n",
    "from utils import print_evaluation_report, evaluate_entity_spans\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 90,320\n",
      "Validation samples: 10,036\n"
     ]
    }
   ],
   "source": [
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "# Load data\n",
    "train_data = load_jsonl('train_split.jsonl')\n",
    "val_data = load_jsonl('val_split.jsonl')\n",
    "\n",
    "print(f\"Training samples: {len(train_data):,}\")\n",
    "print(f\"Validation samples: {len(val_data):,}\")\n",
    "\n",
    "# Extract tokens and tags\n",
    "train_tokens = [sample['tokens'] for sample in train_data]\n",
    "train_tags = [sample['ner_tags'] for sample in train_data]\n",
    "\n",
    "val_tokens = [sample['tokens'] for sample in val_data]\n",
    "val_tags = [sample['ner_tags'] for sample in val_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Vocabularies\n",
    "\n",
    "**Lample (2016) settings:**\n",
    "- Word frequency threshold: Not specified (we'll use 5 like Ma & Hovy)\n",
    "- Character embedding: 25d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vocabulary size: 15,092 (min freq = 5)\n"
     ]
    }
   ],
   "source": [
    "# Build word vocabulary\n",
    "word_counts = Counter()\n",
    "for tokens in train_tokens:\n",
    "    word_counts.update(tokens)\n",
    "\n",
    "MIN_WORD_FREQ = 5\n",
    "word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "for word, count in word_counts.items():\n",
    "    if count >= MIN_WORD_FREQ:\n",
    "        word2idx[word] = len(word2idx)\n",
    "\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "vocab_size = len(word2idx)\n",
    "\n",
    "print(f\"Word vocabulary size: {vocab_size:,} (min freq = {MIN_WORD_FREQ})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character vocabulary size: 97\n"
     ]
    }
   ],
   "source": [
    "# Build character vocabulary\n",
    "char2idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "\n",
    "chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 .,!?:;\\'\"()-[]{}@#$%^&*+=/<>\\\\|`~_'\n",
    "for char in chars:\n",
    "    if char not in char2idx:\n",
    "        char2idx[char] = len(char2idx)\n",
    "\n",
    "idx2char = {idx: char for char, idx in char2idx.items()}\n",
    "char_vocab_size = len(char2idx)\n",
    "\n",
    "print(f\"Character vocabulary size: {char_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NER tags: 15\n",
      "Tags: ['O', 'B-ORG', 'I-ORG', 'B-Facility', 'I-Facility', 'B-OtherPER', 'I-OtherPER', 'B-Politician', 'I-Politician', 'B-HumanSettlement', 'I-HumanSettlement', 'B-Artist', 'I-Artist', 'B-PublicCorp', 'I-PublicCorp']\n"
     ]
    }
   ],
   "source": [
    "# Build tag vocabulary\n",
    "tag2idx = {}\n",
    "for tags in train_tags:\n",
    "    for tag in tags:\n",
    "        if tag not in tag2idx:\n",
    "            tag2idx[tag] = len(tag2idx)\n",
    "\n",
    "idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
    "num_tags = len(tag2idx)\n",
    "\n",
    "print(f\"Number of NER tags: {num_tags}\")\n",
    "print(f\"Tags: {list(tag2idx.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Pre-trained Word Embeddings (GloVe)\n",
    "\n",
    "**Lample (2016) uses GloVe 100d**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GloVe embeddings...\n",
      "GloVe embeddings loaded! Dimension: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading GloVe embeddings...\")\n",
    "glove_model = api.load('glove-wiki-gigaword-100')\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "print(f\"GloVe embeddings loaded! Dimension: {EMBEDDING_DIM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words found in GloVe: 14,897 / 15,092 (98.7%)\n"
     ]
    }
   ],
   "source": [
    "# Create embedding matrix\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "\n",
    "found = 0\n",
    "for word, idx in word2idx.items():\n",
    "    if word in ['<PAD>', '<UNK>']:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        embedding_matrix[idx] = glove_model[word.lower()]\n",
    "        found += 1\n",
    "    except KeyError:\n",
    "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(EMBEDDING_DIM,))\n",
    "\n",
    "# Special tokens\n",
    "embedding_matrix[word2idx['<PAD>']] = np.zeros(EMBEDDING_DIM)\n",
    "embedding_matrix[word2idx['<UNK>']] = np.random.normal(scale=0.6, size=(EMBEDDING_DIM,))\n",
    "\n",
    "print(f\"Words found in GloVe: {found:,} / {vocab_size:,} ({found/vocab_size*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 90320 samples\n",
      "Val dataset: 10036 samples\n"
     ]
    }
   ],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, tokens_list, tags_list, word2idx, char2idx, tag2idx):\n",
    "        self.tokens_list = tokens_list\n",
    "        self.tags_list = tags_list\n",
    "        self.word2idx = word2idx\n",
    "        self.char2idx = char2idx\n",
    "        self.tag2idx = tag2idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tokens_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.tokens_list[idx]\n",
    "        tags = self.tags_list[idx]\n",
    "        \n",
    "        # Words\n",
    "        word_ids = [self.word2idx.get(token, self.word2idx['<UNK>']) for token in tokens]\n",
    "        \n",
    "        # Characters (variable length - will be padded in collate_fn)\n",
    "        char_ids = []\n",
    "        for token in tokens:\n",
    "            chars = [self.char2idx.get(c, self.char2idx['<UNK>']) for c in token]\n",
    "            char_ids.append(chars)\n",
    "        \n",
    "        # Tags\n",
    "        tag_ids = [self.tag2idx[tag] for tag in tags]\n",
    "        \n",
    "        return {\n",
    "            'word_ids': word_ids,\n",
    "            'char_ids': char_ids,  # List of lists (variable length)\n",
    "            'tag_ids': tag_ids,\n",
    "            'length': len(tokens)\n",
    "        }\n",
    "\n",
    "train_dataset = NERDataset(train_tokens, train_tags, word2idx, char2idx, tag2idx)\n",
    "val_dataset = NERDataset(val_tokens, val_tags, word2idx, char2idx, tag2idx)\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Val dataset: {len(val_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 9032 (batch size = 10)\n",
      "Val batches: 1004\n"
     ]
    }
   ],
   "source": [
    "# Collate function for character BiLSTM - filters empty sequences\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate for variable-length characters - filters empty sequences\"\"\"\n",
    "    # Sort by length\n",
    "    batch = sorted(batch, key=lambda x: x['length'], reverse=True)\n",
    "    \n",
    "    # Filter out empty sequences BEFORE processing\n",
    "    batch = [item for item in batch if item['length'] > 0]\n",
    "    \n",
    "    # Handle completely empty batch\n",
    "    if len(batch) == 0:\n",
    "        return {\n",
    "            'word_ids': torch.zeros((0, 0), dtype=torch.long),\n",
    "            'char_ids': torch.zeros((0, 0), dtype=torch.long),\n",
    "            'char_lens': [],\n",
    "            'tag_ids': torch.zeros((0, 0), dtype=torch.long),\n",
    "            'lengths': [],\n",
    "            'mask': torch.zeros((0, 0), dtype=torch.bool)\n",
    "        }\n",
    "    \n",
    "    word_ids = [torch.LongTensor(item['word_ids']) for item in batch]\n",
    "    tag_ids = [torch.LongTensor(item['tag_ids']) for item in batch]\n",
    "    lengths = [item['length'] for item in batch]\n",
    "    \n",
    "    # Pad word and tag sequences\n",
    "    word_ids_padded = pad_sequence(word_ids, batch_first=True, padding_value=word2idx['<PAD>'])\n",
    "    tag_ids_padded = pad_sequence(tag_ids, batch_first=True, padding_value=tag2idx['O'])\n",
    "    \n",
    "    # For characters: need to pad each word's character sequence\n",
    "    # char_ids is list of lists of lists: batch -> words -> chars\n",
    "    char_ids_all = []  # Will store all character sequences flattened\n",
    "    char_lens_all = []  # Length of each character sequence\n",
    "    \n",
    "    for item in batch:\n",
    "        for word_chars in item['char_ids']:\n",
    "            char_ids_all.append(torch.LongTensor(word_chars))\n",
    "            char_lens_all.append(len(word_chars))\n",
    "    \n",
    "    # Pad character sequences\n",
    "    char_ids_padded = pad_sequence(char_ids_all, batch_first=True, padding_value=char2idx['<PAD>'])\n",
    "    \n",
    "    # Create mask\n",
    "    max_len = word_ids_padded.size(1)\n",
    "    batch_size = len(batch)\n",
    "    mask = torch.zeros((batch_size, max_len), dtype=torch.bool)\n",
    "    for i, length in enumerate(lengths):\n",
    "        mask[i, :length] = True\n",
    "    \n",
    "    return {\n",
    "        'word_ids': word_ids_padded,\n",
    "        'char_ids': char_ids_padded,\n",
    "        'char_lens': char_lens_all,\n",
    "        'tag_ids': tag_ids_padded,\n",
    "        'lengths': lengths,\n",
    "        'mask': mask\n",
    "    }\n",
    "\n",
    "# Create DataLoaders\n",
    "BATCH_SIZE = 10  # Following paper settings\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)} (batch size = {BATCH_SIZE})\")\n",
    "print(f\"Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Architecture\n",
    "\n",
    "**Key difference: Character-level BiLSTM (not CNN)**\n",
    "\n",
    "```\n",
    "Characters â†’ Char Embedding (25d) â†’ Char BiLSTM (25 hidden Ã— 2) â†’ 50d\n",
    "Words â†’ Word Embedding (100d GloVe)\n",
    "    â†“\n",
    "Concat (150d) â†’ Word BiLSTM (100 hidden Ã— 2) â†’ 200d\n",
    "    â†“\n",
    "Dropout (0.5) â†’ Linear â†’ CRF\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture defined (Lample 2016 - Char BiLSTM)!\n"
     ]
    }
   ],
   "source": [
    "class CharBiLSTM(nn.Module):\n",
    "    \"\"\"Character-level BiLSTM (Lample et al. 2016)\"\"\"\n",
    "    def __init__(self, char_vocab_size, char_emb_dim, char_hidden_dim):\n",
    "        super().__init__()\n",
    "        self.char_embedding = nn.Embedding(char_vocab_size, char_emb_dim, padding_idx=0)\n",
    "        \n",
    "        # BiLSTM over characters\n",
    "        self.char_lstm = nn.LSTM(\n",
    "            input_size=char_emb_dim,\n",
    "            hidden_size=char_hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "    def forward(self, char_ids, char_lens):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            char_ids: (total_words, max_char_len) - all words in batch flattened\n",
    "            char_lens: list of character lengths for each word\n",
    "        Returns:\n",
    "            char_features: (total_words, char_hidden_dim * 2)\n",
    "        \"\"\"\n",
    "        # Embed characters\n",
    "        char_embeds = self.char_embedding(char_ids)  # (total_words, max_char_len, char_emb_dim)\n",
    "        \n",
    "        # Pack padded sequence for efficiency\n",
    "        char_lens_tensor = torch.LongTensor(char_lens)\n",
    "        \n",
    "        # Clamp lengths to at least 1 to avoid pack_padded_sequence errors\n",
    "        char_lens_clamped = torch.clamp(char_lens_tensor, min=1)\n",
    "        \n",
    "        packed = pack_padded_sequence(\n",
    "            char_embeds, char_lens_clamped.cpu(), \n",
    "            batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        \n",
    "        # BiLSTM\n",
    "        packed_output, (hidden, _) = self.char_lstm(packed)\n",
    "        \n",
    "        # Take final hidden states from both directions\n",
    "        # hidden: (2, total_words, char_hidden_dim) -> (total_words, char_hidden_dim * 2)\n",
    "        char_features = torch.cat([hidden[0], hidden[1]], dim=-1)\n",
    "        \n",
    "        return char_features\n",
    "\n",
    "\n",
    "class BiLSTM_CRF_Lample2016(nn.Module):\n",
    "    \"\"\"BiLSTM-CRF with Char-BiLSTM (Lample et al. 2016)\"\"\"\n",
    "    def __init__(self, vocab_size, char_vocab_size, embedding_dim, char_emb_dim,\n",
    "                 char_hidden_dim, lstm_hidden_dim, num_tags, embedding_matrix=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Word embeddings\n",
    "        self.word_embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        if embedding_matrix is not None:\n",
    "            self.word_embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "            self.word_embedding.weight.requires_grad = True\n",
    "        \n",
    "        # Character BiLSTM\n",
    "        self.char_bilstm = CharBiLSTM(char_vocab_size, char_emb_dim, char_hidden_dim)\n",
    "        self.char_output_dim = char_hidden_dim * 2\n",
    "        \n",
    "        # Word-level BiLSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim + (char_hidden_dim * 2),  # word + char features\n",
    "            hidden_size=lstm_hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(lstm_hidden_dim * 2, num_tags)\n",
    "        \n",
    "        # CRF\n",
    "        self.crf = CRF(num_tags, batch_first=True)\n",
    "    \n",
    "    def forward(self, word_ids, char_ids, char_lens, tags=None, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            word_ids: (batch, seq_len)\n",
    "            char_ids: (total_words, max_char_len) - flattened\n",
    "            char_lens: list of char lengths (length = total_words)\n",
    "            tags: (batch, seq_len)\n",
    "            mask: (batch, seq_len)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = word_ids.size()\n",
    "        \n",
    "        # Word embeddings\n",
    "        word_embeds = self.word_embedding(word_ids)  # (batch, seq_len, word_emb_dim)\n",
    "        \n",
    "        # Character features for all words\n",
    "        char_features = self.char_bilstm(char_ids, char_lens)  # (total_words, char_hidden*2)\n",
    "        \n",
    "        # Reshape char features to match word embeddings\n",
    "        # The char_features are ordered as: word[0,0], word[0,1], ..., word[0,seq_len-1], word[1,0], ...\n",
    "        # We need to split them back by checking the actual total\n",
    "        total_words = char_features.size(0)\n",
    "        expected_words = batch_size * seq_len\n",
    "        \n",
    "        # If there are fewer char features than expected (due to variable length sequences),\n",
    "        # we need to be more careful about how we reshape\n",
    "        if total_words == expected_words:\n",
    "            # Simple case: just reshape\n",
    "            char_features_batched = char_features.view(batch_size, seq_len, self.char_output_dim)\n",
    "        else:\n",
    "            # Complex case: we have variable length sequences, need to manually assign\n",
    "            # This shouldn't happen with our collate_fn that pads, but let's handle it\n",
    "            char_features_batched = torch.zeros(\n",
    "                batch_size, seq_len, self.char_output_dim,\n",
    "                device=char_features.device, dtype=char_features.dtype\n",
    "            )\n",
    "            \n",
    "            char_idx = 0\n",
    "            for b in range(batch_size):\n",
    "                for s in range(seq_len):\n",
    "                    if char_idx < total_words:\n",
    "                        char_features_batched[b, s] = char_features[char_idx]\n",
    "                        char_idx += 1\n",
    "        \n",
    "        # Concatenate word and character features\n",
    "        combined = torch.cat([word_embeds, char_features_batched], dim=-1)\n",
    "        \n",
    "        # Word-level BiLSTM\n",
    "        lstm_out, _ = self.lstm(combined)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        \n",
    "        # Emission scores\n",
    "        emissions = self.fc(lstm_out)\n",
    "        \n",
    "        if tags is not None:\n",
    "            loss = -self.crf(emissions, tags, mask=mask, reduction='mean')\n",
    "            return loss\n",
    "        else:\n",
    "            predictions = self.crf.decode(emissions, mask=mask)\n",
    "            return predictions\n",
    "\n",
    "print(\"Model architecture defined (Lample 2016 - Char BiLSTM)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Initialize Model\n",
    "\n",
    "**Lample (2016) hyperparameters:**\n",
    "- Char embedding: **25d**\n",
    "- Char BiLSTM hidden: **25** per direction (50 total)\n",
    "- Word BiLSTM hidden: **100** per direction (200 total)\n",
    "- Optimizer: **SGD + momentum**\n",
    "- Learning rate: **0.01**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ LAMPLE (2016) CONFIGURATION:\n",
      "  Character encoding: BiLSTM (not CNN!)\n",
      "  Char embedding: 25d\n",
      "  Char BiLSTM hidden: 25 Ã— 2 = 50d\n",
      "  Word BiLSTM hidden: 100 Ã— 2 = 200d\n",
      "  Optimizer: SGD + momentum=0.9\n",
      "  Learning rate: 0.01 with decay\n",
      "  Batch size: 10\n",
      "  Total parameters: 1,726,895\n"
     ]
    }
   ],
   "source": [
    "# LAMPLE (2016) HYPERPARAMETERS\n",
    "CHAR_EMB_DIM = 25       # Paper: 25d\n",
    "CHAR_HIDDEN_DIM = 25    # Paper: 25 (bidirectional = 50 total)\n",
    "LSTM_HIDDEN_DIM = 100   # Paper: 100 (bidirectional = 200 total)\n",
    "LEARNING_RATE = 0.01    # Paper: 0.01\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "# Initialize model\n",
    "model = BiLSTM_CRF_Lample2016(\n",
    "    vocab_size=vocab_size,\n",
    "    char_vocab_size=char_vocab_size,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    char_emb_dim=CHAR_EMB_DIM,\n",
    "    char_hidden_dim=CHAR_HIDDEN_DIM,\n",
    "    lstm_hidden_dim=LSTM_HIDDEN_DIM,\n",
    "    num_tags=num_tags,\n",
    "    embedding_matrix=embedding_matrix\n",
    ").to(device)\n",
    "\n",
    "# PAPER OPTIMIZER: SGD with momentum\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=3, verbose=True\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"\\nðŸŽ¯ LAMPLE (2016) CONFIGURATION:\")\n",
    "print(f\"  Character encoding: BiLSTM (not CNN!)\")\n",
    "print(f\"  Char embedding: {CHAR_EMB_DIM}d\")\n",
    "print(f\"  Char BiLSTM hidden: {CHAR_HIDDEN_DIM} Ã— 2 = {CHAR_HIDDEN_DIM*2}d\")\n",
    "print(f\"  Word BiLSTM hidden: {LSTM_HIDDEN_DIM} Ã— 2 = {LSTM_HIDDEN_DIM*2}d\")\n",
    "print(f\"  Optimizer: SGD + momentum=0.9\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE} with decay\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Total parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined!\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    \"\"\"Training loop - empty sequences already filtered in collate_fn\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    pbar = tqdm(data_loader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for batch in pbar:\n",
    "        # Skip empty batches (rare, but possible)\n",
    "        if len(batch['lengths']) == 0:\n",
    "            continue\n",
    "            \n",
    "        word_ids = batch['word_ids'].to(device)\n",
    "        char_ids = batch['char_ids'].to(device)\n",
    "        char_lens = batch['char_lens']\n",
    "        tag_ids = batch['tag_ids'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = model(word_ids, char_ids, char_lens, tag_ids, mask)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / max(num_batches, 1)\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, device):\n",
    "    \"\"\"Evaluate - empty sequences already filtered in collate_fn\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_true_tags = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(data_loader, desc=\"Evaluating\", leave=False)\n",
    "        \n",
    "        for batch in pbar:\n",
    "            # Skip empty batches\n",
    "            if len(batch['lengths']) == 0:\n",
    "                continue\n",
    "                \n",
    "            word_ids = batch['word_ids'].to(device)\n",
    "            char_ids = batch['char_ids'].to(device)\n",
    "            char_lens = batch['char_lens']\n",
    "            tag_ids = batch['tag_ids'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "            lengths = batch['lengths']\n",
    "            \n",
    "            predictions = model(word_ids, char_ids, char_lens, mask=mask)\n",
    "            \n",
    "            # Convert to tags\n",
    "            for i, (pred, length) in enumerate(zip(predictions, lengths)):\n",
    "                pred_tags = [idx2tag[idx] for idx in pred[:length]]\n",
    "                true_tags = [idx2tag[tag_ids[i][j].item()] for j in range(length)]\n",
    "                \n",
    "                all_predictions.append(pred_tags)\n",
    "                all_true_tags.append(true_tags)\n",
    "    \n",
    "    return all_true_tags, all_predictions\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with LAMPLE (2016) settings...\n",
      "\n",
      "================================================================================\n",
      "Configuration:\n",
      "  - Character encoding: BiLSTM (Lample) vs CNN (Ma & Hovy)\n",
      "  - Char BiLSTM: 25Ã—2=50d output\n",
      "  - Word BiLSTM: 100Ã—2=200d output\n",
      "  - Original paper result: 90.94% F1 on CoNLL-2003\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m epoch_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[1;32m     23\u001b[0m val_true_tags, val_pred_tags \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, device)\n",
      "Cell \u001b[0;32mIn[28], line 22\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, optimizer, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m model(word_ids, char_ids, char_lens, tag_ids, mask)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Gradient clipping\u001b[39;00m\n\u001b[1;32m     25\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5.0\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting training with LAMPLE (2016) settings...\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Configuration:\")\n",
    "print(f\"  - Character encoding: BiLSTM (Lample) vs CNN (Ma & Hovy)\")\n",
    "print(f\"  - Char BiLSTM: 25Ã—2=50d output\")\n",
    "print(f\"  - Word BiLSTM: 100Ã—2=200d output\")\n",
    "print(f\"  - Original paper result: 90.94% F1 on CoNLL-2003\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "best_f1 = 0\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "training_start = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    \n",
    "    # Evaluate\n",
    "    val_true_tags, val_pred_tags = evaluate(model, val_loader, device)\n",
    "    \n",
    "    # Calculate F1\n",
    "    results = evaluate_entity_spans(val_true_tags, val_pred_tags, val_tokens)\n",
    "    val_f1 = results['f1']\n",
    "    val_precision = results['precision']\n",
    "    val_recall = results['recall']\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:2d}/{NUM_EPOCHS} | \"\n",
    "          f\"Loss: {train_loss:.4f} | \"\n",
    "          f\"Val P: {val_precision:.4f} R: {val_recall:.4f} F1: {val_f1:.4f} | \"\n",
    "          f\"LR: {current_lr:.5f} | \"\n",
    "          f\"Time: {epoch_time:.1f}s\")\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_f1)\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        os.makedirs('models', exist_ok=True)\n",
    "        torch.save(model.state_dict(), 'models/bilstm_crf_lample2016_best.pt')\n",
    "        print(f\"  â†’ New best F1! Model saved.\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping after {epoch+1} epochs (patience={patience})\")\n",
    "            break\n",
    "\n",
    "training_time = time.time() - training_start\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTraining completed in {training_time:.1f}s ({training_time/60:.1f} minutes)\")\n",
    "print(f\"Best validation F1: {best_f1:.4f}\")\n",
    "print(f\"\\nNote: This used Lample et al. (2016) with Char-BiLSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Load Best Model and Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('models/bilstm_crf_lample2016_best.pt'))\n",
    "model.eval()\n",
    "\n",
    "print(\"Best model loaded!\")\n",
    "\n",
    "# Final evaluation\n",
    "val_true_tags, val_pred_tags = evaluate(model, val_loader, device)\n",
    "\n",
    "# Comprehensive report\n",
    "print_evaluation_report(\n",
    "    val_true_tags,\n",
    "    val_pred_tags,\n",
    "    val_tokens,\n",
    "    model_name=\"BiLSTM-CRF with Char-BiLSTM (Lample 2016)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vocabularies\n",
    "vocab_data = {\n",
    "    'word2idx': word2idx,\n",
    "    'char2idx': char2idx,\n",
    "    'tag2idx': tag2idx,\n",
    "    'idx2word': idx2word,\n",
    "    'idx2char': idx2char,\n",
    "    'idx2tag': idx2tag\n",
    "}\n",
    "\n",
    "with open('models/bilstm_crf_lample2016_vocab.pkl', 'wb') as f:\n",
    "    pickle.dump(vocab_data, f)\n",
    "\n",
    "print(\"Vocabularies saved!\")\n",
    "\n",
    "# Save results\n",
    "final_results = evaluate_entity_spans(val_true_tags, val_pred_tags, val_tokens)\n",
    "\n",
    "results_summary = {\n",
    "    'model': 'BiLSTM-CRF with Char-BiLSTM (Lample et al. 2016)',\n",
    "    'precision': final_results['precision'],\n",
    "    'recall': final_results['recall'],\n",
    "    'f1': final_results['f1'],\n",
    "    'training_time': training_time,\n",
    "    'num_epochs': epoch + 1,\n",
    "    'hyperparameters': {\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "        'char_emb_dim': CHAR_EMB_DIM,\n",
    "        'char_lstm_hidden': CHAR_HIDDEN_DIM,\n",
    "        'char_output_dim': CHAR_HIDDEN_DIM * 2,\n",
    "        'lstm_hidden_dim': LSTM_HIDDEN_DIM,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'optimizer': 'SGD with momentum=0.9',\n",
    "        'lr_scheduler': 'ReduceLROnPlateau',\n",
    "        'dropout': 0.5,\n",
    "        'min_word_freq': MIN_WORD_FREQ\n",
    "    },\n",
    "    'paper_reference': 'Lample et al. (2016) - Neural Architectures for Named Entity Recognition',\n",
    "    'paper_result_conll2003': '90.94% F1',\n",
    "    'char_encoding': 'BiLSTM (not CNN)'\n",
    "}\n",
    "\n",
    "with open('models/bilstm_crf_lample2016_results.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(\"Results saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary\n",
    "\n",
    "### Lample et al. (2016) - Paper-Exact Implementation:\n",
    "\n",
    "This notebook replicates **Lample et al. (2016)** which uses:\n",
    "\n",
    "âœ… **Character encoding**: BiLSTM (25d hidden Ã— 2 directions = 50d output)  \n",
    "âœ… **Word BiLSTM**: 100 hidden Ã— 2 = 200d output  \n",
    "âœ… **Optimizer**: SGD + momentum=0.9  \n",
    "âœ… **Learning rate**: 0.01 with decay  \n",
    "âœ… **Batch size**: 10  \n",
    "\n",
    "### Comparison of Three Implementations:\n",
    "\n",
    "| Feature | M4.ipynb | M4_Paper_Exact.ipynb | M4_Lample2016.ipynb |\n",
    "|---------|----------|---------------------|--------------------|\n",
    "| **Char encoding** | CNN (30d) | CNN (30d) | **BiLSTM (50d)** |\n",
    "| **LSTM hidden** | 256 | 100 | 100 |\n",
    "| **Optimizer** | Adam | SGD | SGD |\n",
    "| **Batch size** | 32 | 10 | 10 |\n",
    "| **Paper** | â€” | Ma & Hovy 2016 | Lample 2016 |\n",
    "| **Paper F1** | â€” | 91.21% | 90.94% |\n",
    "\n",
    "### Key Difference: Character Encoding\n",
    "\n",
    "**Lample (2016)**: Uses BiLSTM to process character sequences\n",
    "- Pro: Can capture longer-range character patterns\n",
    "- Con: Slower (sequential processing)\n",
    "\n",
    "**Ma & Hovy (2016)**: Uses CNN to process characters\n",
    "- Pro: Faster (parallel processing)\n",
    "- Con: Limited receptive field (kernel size 3)\n",
    "\n",
    "### Expected Results:\n",
    "\n",
    "**Paper (CoNLL-2003)**: 90.94% F1  \n",
    "**Your dataset**: 80-85% F1 (harder - 15 entity types)\n",
    "\n",
    "### Which is Better?\n",
    "\n",
    "Both papers achieved similar results (~91% F1 on CoNLL-2003):  \n",
    "- **Ma & Hovy (CNN)**: 91.21% F1  \n",
    "- **Lample (BiLSTM)**: 90.94% F1  \n",
    "\n",
    "CNN is slightly better and faster, which is why it became more popular!\n",
    "\n",
    "### Reference:\n",
    "\n",
    "**Lample, G., Ballesteros, M., Subramanian, S., Kawakami, K., & Dyer, C. (2016)**. Neural architectures for named entity recognition. In Proceedings of NAACL 2016.\n",
    "- Paper: https://arxiv.org/abs/1603.01360\n",
    "- Result: 90.94% F1 on CoNLL-2003 English NER\n",
    "- Key innovation: Character-level BiLSTM for word representations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
